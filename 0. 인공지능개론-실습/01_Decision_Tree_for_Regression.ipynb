{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"C6gZm1SbmxYt"},"outputs":[],"source":["%reset -f"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2677,"status":"ok","timestamp":1714721686601,"user":{"displayName":"Seunggyu Byeon","userId":"08737581863014098711"},"user_tz":-540},"id":"WgTSQ1pEoOnz","outputId":"6f47c2e3-2c5c-40af-8f31-ca55bd7ac707"},"outputs":[{"output_type":"stream","name":"stdout","text":["(20640, 8)\n","(20640,)\n","['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n","['MedHouseVal']\n",".. _california_housing_dataset:\n","\n","California Housing dataset\n","--------------------------\n","\n","**Data Set Characteristics:**\n","\n","    :Number of Instances: 20640\n","\n","    :Number of Attributes: 8 numeric, predictive attributes and the target\n","\n","    :Attribute Information:\n","        - MedInc        median income in block group\n","        - HouseAge      median house age in block group\n","        - AveRooms      average number of rooms per household\n","        - AveBedrms     average number of bedrooms per household\n","        - Population    block group population\n","        - AveOccup      average number of household members\n","        - Latitude      block group latitude\n","        - Longitude     block group longitude\n","\n","    :Missing Attribute Values: None\n","\n","This dataset was obtained from the StatLib repository.\n","https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n","\n","The target variable is the median house value for California districts,\n","expressed in hundreds of thousands of dollars ($100,000).\n","\n","This dataset was derived from the 1990 U.S. census, using one row per census\n","block group. A block group is the smallest geographical unit for which the U.S.\n","Census Bureau publishes sample data (a block group typically has a population\n","of 600 to 3,000 people).\n","\n","A household is a group of people residing within a home. Since the average\n","number of rooms and bedrooms in this dataset are provided per household, these\n","columns may take surprisingly large values for block groups with few households\n","and many empty houses, such as vacation resorts.\n","\n","It can be downloaded/loaded using the\n",":func:`sklearn.datasets.fetch_california_housing` function.\n","\n",".. topic:: References\n","\n","    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n","      Statistics and Probability Letters, 33 (1997) 291-297\n","\n"]}],"source":["from sklearn.datasets import fetch_california_housing\n","\n","california_housing = fetch_california_housing()\n","\n","print(california_housing.data.shape)\n","print(california_housing.target.shape)\n","\n","print(california_housing.feature_names)\n","print(california_housing.target_names)\n","\n","print(california_housing.DESCR)\n","\n","X = california_housing.data\n","y = california_housing.target\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":327,"status":"ok","timestamp":1714721729900,"user":{"displayName":"Seunggyu Byeon","userId":"08737581863014098711"},"user_tz":-540},"id":"B7XDWNJUnEzv"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","#import jsonpickle\n","\n","class Node:\n","    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n","        self.feature_index = feature_index    # 특징(Feature)의 인덱스\n","        self.threshold = threshold            # 분할 기준값\n","        self.left = left                      # 왼쪽 서브트리\n","        self.right = right                    # 오른쪽 서브트리\n","        self.value = value                    # 리프 노드의 값\n","\n","    def to_dict(self):\n","        return {\n","            'feature_index': self.feature_index,\n","            'threshold': self.threshold,\n","            'left': self.left.to_dict() if isinstance(self.left, Node) else self.left,\n","            'right': self.right.to_dict() if isinstance(self.right, Node) else self.right,\n","            'value': self.value\n","        }\n","\n","    @classmethod\n","    def from_dict(cls, data):\n","        if data is None:\n","            return None\n","        return cls(\n","            feature_index = data['feature_index'],\n","            threshold = data['threshold'],\n","            left = cls.from_dict(data['left']),\n","            right = cls.from_dict(data['right']),\n","            value = data['value']\n","        )\n","\n","# Standard CART (Classification And Regression Tree)\n","class RegressionTree:\n","    def __init__(self, max_depth=None, min_samples_split=2):\n","        self.max_depth = max_depth\n","        self.min_samples_split = min_samples_split\n","        self.tree = None\n","\n","    def fit(self, X, y):\n","        if isinstance(X, pd.DataFrame):\n","            X = X.to_numpy()\n","        if isinstance(y, pd.Series):\n","            y = y.values\n","        self.tree = self._build_tree(X, y, depth=0)\n","\n","    def _variance_reduction(self, y, left_y, right_y):\n","        variance = np.var(y)\n","\n","        left_var = np.var(left_y)\n","        right_var = np.var(right_y)\n","\n","        frac_left = len(left_y) / len(y)\n","        frac_right = len(right_y) / len(y)\n","\n","        return variance - (frac_left * left_var + frac_right * right_var)\n","\n","    def _build_tree(self, X, y, depth):\n","        n_samples, n_features = X.shape\n","        variance = np.var(y)\n","\n","        if variance == 0 or depth == self.max_depth or n_samples < self.min_samples_split:\n","            return np.mean(y)\n","\n","        best_feature, best_threshold = None, None\n","        best_gain = -np.inf\n","\n","        for feature_index in range(n_features):\n","            thresholds = np.unique(X[:, feature_index])\n","            for threshold in thresholds:\n","                left_indices = X[:, feature_index] < threshold\n","                right_indices = ~left_indices\n","\n","                if len(y[left_indices]) > 0 and len(y[right_indices]) > 0:\n","                    gain = self._variance_reduction(y, y[left_indices], y[right_indices])\n","                    if gain > best_gain:\n","                        best_gain = gain\n","                        best_feature = feature_index\n","                        best_threshold = threshold\n","\n","        if best_gain == -np.inf:            # 분할 시 Gain이 없음\n","            return np.mean(y)\n","\n","        left_indices = X[:, best_feature] < best_threshold\n","        right_indices = ~left_indices\n","        left = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n","        right = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n","\n","        return Node(feature_index=best_feature, threshold=best_threshold, left=left, right=right)\n","\n","    def predict(self, X):\n","        if isinstance(X, pd.DataFrame):\n","            X = X.values  # DataFrame을 NumPy 배열로 변환\n","        return np.array([self._predict_tree(x, self.tree) for x in X])\n","\n","    def _predict_tree(self, x, node):\n","        if isinstance(node, float):  # Leaf인 경우\n","            return node\n","        if x[node.feature_index] < node.threshold:\n","            return self._predict_tree(x, node.left)\n","        else:\n","            return self._predict_tree(x, node.right)\n","\n","    def to_dict(self):\n","        return self.tree.to_dict()\n","\n","    def export_tree_as_dot(self, feature_names=None):\n","        if feature_names is None:\n","            feature_names = [f\"Feature {i}\" for i in range(len(self.tree.feature_index))]\n","\n","        dot_data = \"digraph Tree {\\nnode [shape=box] ;\\n\"\n","        dot_data += self._build_dot(self.tree, feature_names)\n","        dot_data += \"}\"\n","        return dot_data\n","\n","    def _build_dot(self, node, feature_names):\n","        dot = \"\"\n","        if isinstance(node, Node):\n","            if node.feature_index is not None and node.feature_index < len(feature_names) and feature_names[node.feature_index] is not None:\n","                if node.value is not None:\n","                    dot += f'N{hash(node)} [label=\"{feature_names[node.feature_index]} <= {node.threshold:.2f}\\\\nvariance reduction: {node.value:.4f}\"] ;\\n'\n","                else:\n","                    dot += f'N{hash(node)} [label=\"{feature_names[node.feature_index]} <= {node.threshold:.2f}\"] ;\\n'\n","            else:\n","                dot += f'N{hash(node)} [label=\"value: {node.value:.2f}\"] ;\\n'\n","\n","            if node.left is not None:\n","                dot += f'N{hash(node)} -> N{hash(node.left)} [label=\"True\"] ;\\n'\n","                dot += self._build_dot(node.left, feature_names)\n","            if node.right is not None:\n","                dot += f'N{hash(node)} -> N{hash(node.right)} [label=\"False\"] ;\\n'\n","                dot += self._build_dot(node.right, feature_names)\n","        else:\n","            if node is not None:\n","                dot += f'N{hash(node)} [label=\"value: {node:.2f}\"] ;\\n'\n","\n","        return dot\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AkKaNQOEnc4F"},"outputs":[],"source":["from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error\n","\n","# k-fold 교차 검증 설정 (2만개 당 fold 1개)\n","k = 10\n","kf = KFold(n_splits=k, shuffle=True, random_state=42)\n","mse_scores = []\n","\n","# 트리 하이퍼파라미터\n","tree_depth = 5\n","\n","# k-fold 교차 검증 실행\n","predictions = []\n","reg_tree = []\n","\n","# 예측 결과와 실제 값 수집\n","all_y_true = []\n","all_y_pred = []\n","\n","for train_index, test_index in kf.split(X):\n","    X_train, X_test = X[train_index], X[test_index]\n","\n","    # 입력과 타겟 분리\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    # 모델 생성 및 학습\n","    regression_tree = RegressionTree(max_depth=tree_depth, min_samples_split=5)\n","    regression_tree.fit(X_train, y_train)\n","    reg_tree.append(regression_tree)\n","\n","    # 예측\n","    y_pred = regression_tree.predict(X_test)\n","\n","    # MSE 계산 및 저장\n","    mse = mean_squared_error(y_test, y_pred)\n","    mse_scores.append(mse)\n","    print(f'fold RMSE: {np.sqrt(mse)}')\n","\n","    # 각 폴드의 예측값과 실제값을 튜플로 저장\n","    predictions.append((X_train, y_pred))\n","\n","# k-fold 교차 검증 결과 출력\n","mean_mse = np.mean(mse_scores)\n","std_mse = np.std(mse_scores)\n","print(f\"\\nRMSE: {np.sqrt(mean_mse)}\")\n","print(f\"Mean MSE: {mean_mse}\")\n","print(f\"Std MSE: {std_mse}\")\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNeAy9vWQrJmMVM8i30HtaH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
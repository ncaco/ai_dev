1-3. 두 파라미터 후보의 가능도 비교

로지스틱 회귀에서 가능도는 다음과 같이 계산됩니다:
L(w) = ∏(h_w(x_i)^y_i * (1-h_w(x_i))^(1-y_i))

로그 가능도(log likelihood)는 다음과 같이 계산됩니다:
log L(w) = ∑(y_i*log(h_w(x_i)) + (1-y_i)*log(1-h_w(x_i)))

여기서:
- h_w(x) = 1/(1 + e^(-w·x))는 로지스틱 함수
- y_i는 실제 클래스 (1 또는 0)
- x_i는 입력 벡터 (x_0=1 포함)

주어진 데이터 포인트:
양성 예제(y=1): (1,2), (2,3)
음성 예제(y=0): (3,1), (4,2)

파라미터 후보:
w_1 = (0, -1, 1)
w_2 = (-3, -1, 3)

계산 결과:
w_1 = (0, -1, 1)의 로그 가능도: -2.9769
w_2 = (-3, -1, 3)의 로그 가능도: -2.3816

따라서 w_2가 더 높은 로그 가능도를 가지므로, w_2 = (-3, -1, 3)가 더 나은 파라미터입니다.

1-4. 클래스 경계 도출

로지스틱 회귀에서 클래스 경계는 h_w(x) = 0.5가 되는 지점입니다.
h_w(x) = 0.5일 때, w·x = 0 입니다.

w_2 = (-3, -1, 3), x = (1, x_1, x_2)이므로:
-3·1 + (-1)·x_1 + 3·x_2 = 0
-3 - x_1 + 3x_2 = 0
3x_2 = 3 + x_1
x_2 = (3 + x_1)/3

따라서 클래스 경계는 x_2 = (3 + x_1)/3 직선입니다.

이 직선 위의 모든 점들은 모델의 예측값이 정확히 0.5가 되는 지점입니다.
직선 위쪽 영역은 양성(y=1)으로 예측되고, 아래쪽 영역은 음성(y=0)으로 예측됩니다.

class_boundary.py 스크립트로 이 경계를 시각화할 수 있으며, 양성 예제(검은 점)와 음성 예제(흰 점)와 함께 클래스 경계를 보여줍니다. 